Automatic Keyword 
Automatic Keyword 
Extraction from Learning 
Extraction from Learning 
Objects 
Objects 

Kino Coursey and RadaRada Mihalcea
Mihalcea
Kino Coursey and 

Our Experiments so Far…
Our Experiments so Far…

TextRank
(cid:132)(cid:132) TextRank
–– Graph
Graph --based keyword extraction
based keyword extraction
Wikifier
(cid:132)(cid:132) Wikifier
–– Algorithm based on the Wikipedia repository
Algorithm based on the Wikipedia repository
Combining the two methods
(cid:132)(cid:132) Combining the two methods
–– Intersection based on the “least common 
Intersection based on the “least common 
substring”
substring”
All the evaluations carried out on the History 
(cid:132)(cid:132) All the evaluations carried out on the History 
course data from Phase I
course data from Phase I

1

TextRank: Random walk 
TextRank: Random walk 
algorithms for natural 
algorithms for natural 
language processing
language processing
0.51

A

1.35

B

D
1.17

0.63

C

F

1.47

E
0.36

Rada Mihalcea and Paul Tarau, “TextRank: Bringing Order into Texts” 
EMNLP 2004.

Random Walk Algorithms
Random Walk Algorithms

Usually applied on directed graphs 
(cid:132)(cid:132) Usually applied on directed graphs 
–– From a given vertex, the walker selects at random one 
From a given vertex, the walker selects at random one 
of the out --edges
edges
of the out
Given G = (V,E) a directed graph with 
(cid:132)(cid:132) Given G = (V,E) a directed graph with 
vertices V and edges E
vertices V and edges E
–– In(Vi) = predecessors of Vi
In(Vi) = predecessors of Vi
–– Out(Vi) = successors of Vi
Out(Vi) = successors of Vi
1
∑
VOut
(
|
|)
iVInj
)
(
∈
j
d – damping factor ∈[0,1] (usually 0.85)

d
1(
)
+−=

VS
)(
i

d

VS
(

)

j

2

TextRank for Keyword 
TextRank for Keyword 
Extraction 
Extraction 

Store words in vertices 
(cid:132)(cid:132) Store words in vertices 
Use co --occurrence to draw edges 
occurrence to draw edges 
(cid:132)(cid:132) Use co
Rank graph vertices across the entire 
(cid:132)(cid:132) Rank graph vertices across the entire 
text
text
Pick top N as keywords 
(cid:132)(cid:132) Pick top N as keywords 

An Example
An Example
Compatibility of systems of linear constraints over the set of natural numbers
Criteria of compatibility of a system of linear Diophantine equations, strict 
inequations, and nonstrict inequations are considered. Upper bounds for
components of a minimal set of solutions and algorithms of construction of 
minimal generating sets of solutions for all types of systems are given. 
These criteria and the corresponding algorithms for constructing a minimal 
supporting set of solutions can be used in solving all the considered types of 
systems and systems of mixed types.

types

systems
linear

system

compatibility

criteria

Text Ra n k
numbers (1 .46) 
inequat ions (1 .45) 
l inear  (1 .29) 
diophan t ine (1 .28) 
upper  (0.99) 
bounds (0.99) 
st r ict  (0.77) 

non-strict

natural

upper

strict

algorithms

constraints
solutions

diophantine
equations

Fr equ en cy
syst ems (4) 
t ypes (4) 
solu t ions (3) 
m in imal  (3) 
l inear  (2) 
inequat ions (2) 
algor i t hms (2) 
Keywords by TextRank: linear constraints, linear diophantine equations, natural numbers, non-strict 
inequations, strict inequations, upper bounds
Keywords by human annotators: linear constraints, linear diophantine equations, non-strict 
inequations, set of natural numbers, strict inequations, upper bounds

inequations
construction

numbers

bounds

sets

minimal

components

3

Previous evaluation on 
Previous evaluation on 
INSPEC abstracts
INSPEC abstracts
Evaluation:
(cid:132)(cid:132) Evaluation:
–– 500 INSPEC abstracts
500 INSPEC abstracts
–– collection previously used in 
keyphrase extraction [
collection previously used in keyphrase
extraction [HulthHulth
2003]
2003]
Previous work
(cid:132)(cid:132) Previous work
–– mostly supervised learning
mostly supervised learning
–– [[HulthHulth 2003] 
2003] 
–– training/development/test : 1000/500/500 abstracts
training/development/test : 1000/500/500 abstracts
                Correct
                 Assign ed
 
 
 
Tota l Mean Precision   Reca ll F-measu re
Mean
Tota l
36.2
31.2
43.1
4.2
2,116
13.7
6,784
51.7
7,815
15.6
1,973
3.9
25.2
33.9
33
37.2
29.7
2.8
1,421
9.6
4,788
7,012
14.0
1,523
3.1
21.7
39.9
28.1

Meth od
TextRan k
Ngram  with  tag
NP-chu n ks with  tag
Pa ttern  with  tag

 

Text Wikification
Wikification
Text 

Finding key terms in documents and link 
(cid:132)(cid:132) Finding key terms in documents and link 
them to relevant encyclopedic 
them to relevant encyclopedic 
information. 
information. 

Rada Mihalcea and Andras Csomai, “Linking Documents to Encyclopedic 
Knowledge” CIKM 2007.

4

Wikification Pipeline
Pipeline
Wikification

t
x
e
t
)
r
e
p
y
h
(
 
w
a
R

n
o
i
t
i
s
o
p
m
o
c
e
D

t
x
e
T
 
n
a
e
l
C

s
d
r
o
w
y
e
k
 
d
e
t
c
e
l
e
s
 
h
t
i
w
 
t
x
e
T

Candidate
Extraction

Candidate
Ranking

Extract Sense Definitions
from Sense Inventory

Knowledge-based
Lesk-like Definition
Overlap

Data Driven
Naive Bayes
trained on Wikipedia

Voting

Annotated Text

s
h
d
t
i
r
w
o
 
w
t
x
y
e
e
t
k
)
 
r
d
e
e
p
k
y
n
H
i
(
l

n
o
i
t
i
s
o
p
m
o
c
e
R

Keyword Extraction

Word Sense Disambiguation

Keyword Extraction
Keyword Extraction

Semi --Controlled vocabulary
Controlled vocabulary
(cid:132)(cid:132) Semi
–– Wikipedia article titles and anchor texts (surface forms). 
Wikipedia article titles and anchor texts (surface forms). 
E.g. “USA”, “U.S.”  =  “United States of America”
(cid:132)(cid:132) E.g. “USA”, “U.S.”  =  “United States of America”
–– 1.918.830 terms/phrases
1.918.830 terms/phrases
Vocabulary is broad: “thethe” has 9 senses.
” has 9 senses.
–– Vocabulary is broad: “
Unsupervised keyword extraction
(cid:132)(cid:132) Unsupervised keyword extraction
–– TfTf * * IdfIdf
Wikipedia articles as document collection
(cid:132)(cid:132) Wikipedia articles as document collection
–– ChiChi--squared independence of phrase and text
squared independence of phrase and text
The degree to which it appeared more times than expected by 
(cid:132)(cid:132) The degree to which it appeared more times than expected by 
chance
chance
D
count
(
)
–– Keyphraseness
Keyphraseness : : 
key
D
count
)
(
W

keyword

W

P

(

|

)

=

5

Previous Evaluation on 
Previous Evaluation on 
Wikipedia
Wikipedia
85 documents containing 7.286 links
(cid:132)(cid:132) 85 documents containing 7.286 links
Extract n  n  kkeywords, 
eywords, n=6%n=6%of number of 
of number of 
(cid:132)(cid:132) Extract 
words
words

precision
precision

recall
recall

TfTf * *  IdfIdf
ChiChi--squared
squared
Keyphraseness
Keyphraseness

41.91%
41.91%
41.44%
41.44%
53.37%53.37%

43.73%
43.73%
43.17%
43.17%
55.90%55.90%

FF --
measure
measure
42.82%
42.82%
42.30%
42.30%
54.63%54.63%

Combining TextRank and 
Combining TextRank and 
WikifyWikify !!
Using the strengths of both systems
(cid:132)(cid:132) Using the strengths of both systems
–– TextRank focuses on estimating the 
TextRank focuses on estimating the 
attention given to terms in the text
attention given to terms in the text
–– WikifyWikify focuses on keywords identified by 
focuses on keywords identified by 
a large number of people (Wikipedia)
a large number of people (Wikipedia)
–– Each gets a different set of interesting 
Each gets a different set of interesting 
terms
terms

6

The Violent Agreement 
The Violent Agreement 
Problem
Problem
Two extractors with possibly different but 
(cid:132)(cid:132) Two extractors with possibly different but 
complete segmentations of the same text.
complete segmentations of the same text.
“Mexican traveler” vsvs “Mexican”,” traveler”
–– “Mexican traveler” 
“Mexican”,” traveler”
–– “Birth of Venus 
“Birth of Venus Sandros
Sandros Botticelli” 
Botticelli” vsvs “The Birth 
“The Birth 
Sandros Botticelli” 
of Venus”, “Sandros
Botticelli” 
of Venus”, “
TextRank gets extended noun --chunks while 
chunks while 
(cid:132)(cid:132) TextRank gets extended noun
WikifyWikify ! gets common key phrases or object 
! gets common key phrases or object 
identifiers
identifiers
Need a principled way to find agreement
(cid:132)(cid:132) Need a principled way to find agreement
–– Intersection, Union, longest common substring
Intersection, Union, longest common substring

LCS : Longest Common 
LCS : Longest Common 
Substring
Substring
(cid:132) Problem: Given sequences  x[1..m] and  y[1..n], 
find a longest common subsequence of both.
(cid:132) Example: x=BDABCBADAB and y=BDBCBABDAB, 
– BCB is a common substring and 
– BCBA and BDAB are two LCSs
(cid:132) Common problem for aligning two DNA sequences
(cid:132) Uses a dynamic programming method to find the 
longest common path through both strings
(cid:132) In Subsequence (vs Substring) one allows gaps and 
is related to minimum Edit Distance
http://en.wikibooks.org/wiki/Algorithm_implementation/Strings/Longest_
common_substring
http://en.wikipedia.org/wiki/Longest_common_substring_problem

7

LCS Example
LCS Example

Applies to “Birth of Venus
Birth of Venus Sandros
Sandros Botticelli
Botticelli ” ” vsvs
(cid:132)(cid:132) Applies to “
Botticelli ””
Sandros Botticelli
Birth of Venus”, “”, “Sandros
“The Birth of Venus
“The 
LCS(“Birth of Venus
–– LCS(“
Birth of Venus Sandros
Sandros Botticelli
Botticelli” ,”The 
” ,”The Birth of 
Birth of 
Venus”)=“
”)=“Birth of Venus
Birth of Venus””
Venus
LCS(“Birth of Venus Sandros
–– LCS(“Birth of Venus 
Botticelli”,””,”Sandros
Sandros Botticelli
Sandros
Botticelli”)=“
”)=“Sandros
Sandros Botticelli
Botticelli””
Botticelli
Do a cross comparison for the output of both 
(cid:132)(cid:132) Do a cross comparison for the output of both 
keyword sources keeping the longest match found 
keyword sources keeping the longest match found 
for each 
for each 
Captures coherent fragments
coherent fragmentsfound by both
found by both
(cid:132)(cid:132) Captures 

LCS Algorithm
LCS Algorithm

of

Venus

Sandros

Botticelli

LL
TT
The

BirthSS
function LCSubstr(S[1..m], T[1..n]) 
L := array(0..m, 0..n) 
00
0
0
z := 0  (length of longest match)
0
00
0
ret := {}  (set of longest matches)
01
0
0
for i := 1..m 
20
0
0
for j := 1..n 
3
0
00
Venus
if S[i] = T[j] then L[i,j] := L[i-1,j-1] + 1  (the upper left diagonal) 
if L[i,j] > z  then z := L[i,j]   ret := {}     (new longest found)
if L[i,j] = z  then ret := ret ∪ {S[i-z+1..i]} (an equal longest found)
return ret 
Returns set of all matches of maximal length in one pass throughthe two 
strings

0
0
0
0
0

Birth

of

0
0
0
0
0

8

Intersection and Union
Intersection and Union

Intersection
(cid:132)(cid:132) Intersection
–– Create a list of words and phrases 
Create a list of words and phrases 
common to both list
common to both list
Union
(cid:132)(cid:132) Union
–– Create a list of words and phrases on 
Create a list of words and phrases on 
either list
either list

The System
The System

Source Text

Gold Standard Subject List

Wikifier

TextRank

Evaluator

Statistics

WK-
Articles

Wiki-
keywords

TR-
keywords

LCS-
keywords

Intersection-
keywords

Union-
keywords

LCS

Intersection

Union

9

Evaluations on History LO
Evaluations on History LO

Goal: Given the export of the text of 
(cid:132)(cid:132) Goal: Given the export of the text of 
the Learning Objects determine the 
the Learning Objects determine the 
performance of the various methods
performance of the various methods
–– Precision and recall for basic whole 
Precision and recall for basic whole 
keyword extraction
keyword extraction
–– Individual words in the text being 
Individual words in the text being 
correctly classified as being in the bag --ofof --
correctly classified as being in the bag
gold keywords
gold keywords

Gold Standard and its use
Gold Standard and its use

Each collection of learning objects in a directory has 
(cid:132)(cid:132) Each collection of learning objects in a directory has 
a Dublin Core description file with subjects 
a Dublin Core description file with subjects 
specified. These subjects are the gold standard.
specified. These subjects are the gold standard.
–– Issue 1: One set of keyword for a set of files
Issue 1: One set of keyword for a set of files
–– Issue 2: The set of keywords may not have any direct 
Issue 2: The set of keywords may not have any direct 
reference in any of the text
reference in any of the text
Each file assumes that the gold for it is the gold 
(cid:132)(cid:132) Each file assumes that the gold for it is the gold 
found in the appropriate Dublin file
found in the appropriate Dublin file
A pseudo --document is created consisting of all the 
document is created consisting of all the 
(cid:132)(cid:132) A pseudo
text in the group to test the Dublin keywords 
text in the group to test the Dublin keywords 
against all the text the Dublin file covers
against all the text the Dublin file covers

10

The Flash Card Problem
The Flash Card Problem

Several html files are labeled “flash cards” 
(cid:132)(cid:132) Several html files are labeled “flash cards” 
and contain the following text : “the flash 
and contain the following text : “the flash 
cards”
cards”
Each card has different gold standard sets
(cid:132)(cid:132) Each card has different gold standard sets
Each contains the same data
(cid:132)(cid:132) Each contains the same data
“the flash cards” is not in the gold standard
(cid:132)(cid:132) “the flash cards” is not in the gold standard
Same data + different specified outcome + 
(cid:132)(cid:132) Same data + different specified outcome + 
no valid clues = ???
no valid clues = ???
––http://lit.csci.unt.edu/~rada/Viewer/the%20flash%20card%205.htm.
http://lit.csci.unt.edu/~rada/Viewer/the%20flash%20card%205.htm.
txt.html
txt.html

Relative Recall
Relative Recall

RelativeRecall

0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0

WK WA
TR And LCS Union
RelativeRecall 0.696 0.462 0.261 0.248 0.214 0.799
Relative recall = number of keywords identified out of gold     
standard keywords that appear in the text

11

Keyphrase Precision 
Precision 
Keyphrase

0.18
0.16
0.14
0.12
0.1
0.08
0.06
0.04
0.02
0

WK
WA
TR
And
LCS Union
keyPrecision1 0.0403 0.0267 0.0399 0.0889 0.162 0.0226
keyPrecision2 0.0401 0.028 0.0442 0.0888 0.1617 0.0246

keyPrecision1 =Gold keywords found in KeyList / Total Keylist size
keyPrecision2 =KeyList words found in Gold / Total KeyList size 

Word Level Precision
Word Level Precision

Precis ion

0.35
0.3
0.25
0.2
0.15
0.1
0.05
0

WK
WA
TR
And
LCS Un ion
Precis ion 0.1048 0.0993 0.1365 0.269 0.3008 0.0923

Word level precision = True positive / ( True positive + false positive )  
=  # correct guesses / # guesses

12

Word Level Recall
Word Level Recall

Reca l l

1

0.8

0.6

0.4

0.2

0

WK
WA
TR
And
LCS Un ion
Reca l l 0.7335 0.5312 0.4788 0 .3227 0.2701 0.8219

Word level recall = True Positive / ( True Positive + False negative)
= # correct guesses / # gold words

Word Level F--measure
measure
Word Level F

F-m eas ure

0.35
0.3
0.25
0.2
0.15
0.1
0.05
0

WK
WA
TR
And
LCS Un ion
F-m eas ure 0 .183 0.167 0.212 0.293 0.285 0.166

Word level F-measure = (2* True positive ) / (2*true positive + false 
positive + false negative)
= balance between recall and precision

13

Word Level Accuracy
Word Level Accuracy

Accuracy

1

0.8

0.6

0.4

0.2

0

WK
WA
TR
And
LCS Un ion
Accuracy 0.7622 0.8076 0.8707 0.9434 0.9506 0.6992

Accuracy = (True positive + true negatives)/(all words)
= percentage of total word classifications correct

Word Level Error Rate
Word Level Error Rate

Error

0.35
0.3
0.25
0.2
0.15
0.1
0.05
0

WK
WA
TR
And
LCS
Un ion
Error 0.2378 0.1924 0.1293 0.0566 0.0494 0.3008

Error = 1 – Accuracy
= percentage of total possible misclassified

14

Learning Object Analysis
Learning Object Analysis

Complete Analysis
(cid:132)(cid:132) Complete Analysis
–– http://lit.csci.unt.edu/~rada/Viewer
http://lit.csci.unt.edu/~rada/Viewer
Final Statistics
(cid:132)(cid:132) Final Statistics
–– http://lit.csci.unt.edu/~rada/Viewer/SystemFinalSummary.
http://lit.csci.unt.edu/~rada/Viewer/SystemFinalSummary.
html
html
The Flash Card Problem
(cid:132)(cid:132) The Flash Card Problem
–– http://lit.csci.unt.edu/~rada/Viewer/the%20flash%20card
http://lit.csci.unt.edu/~rada/Viewer/the%20flash%20card
%208.htm.txt.html
%208.htm.txt.html
Boston Tea Party
(cid:132)(cid:132) Boston Tea Party
–– http://lit.csci.unt.edu/~rada/Viewer/boston_gazette.htm.tx
http://lit.csci.unt.edu/~rada/Viewer/boston_gazette.htm.tx
t.html
t.html
Problems Facing the New Country
(cid:132)(cid:132) Problems Facing the New Country
–– http://lit.csci.unt.edu/~rada/Viewer/07_problems_facing_
http://lit.csci.unt.edu/~rada/Viewer/07_problems_facing_
new.htm.txt.html
new.htm.txt.html

Thoughts on Perfomance
Perfomance
Thoughts on 

If you want high recall : Wikifier
Wikifier
(cid:132)(cid:132) If you want high recall : 
–– Relative recall : 69%
Relative recall : 69%
–– Low precision : 4%
Low precision : 4%
If you are interested in balance: LCS
(cid:132)(cid:132) If you are interested in balance: LCS
–– Recall: 21%
Recall: 21%
–– Precision: 16%
Precision: 16%

15

Questions, Thoughts …
Questions, Thoughts …

Gold standard is not really “gold”
(cid:132)(cid:132) Gold standard is not really “gold”
Should we run a separate evaluation 
(cid:132)(cid:132) Should we run a separate evaluation 
with users?
with users?
What will be the end use of the 
(cid:132)(cid:132) What will be the end use of the 
automatic KE? 
automatic KE? 
–– Emphasis on recall vs. emphasis on 
Emphasis on recall vs. emphasis on 
precision
precision
(cid:132)(cid:132) ??????

Next Step …
Next Step …

WikiArticles and 
Explore using the WikiArticles
and 
(cid:132)(cid:132) Explore using the 
WikiRank on them to get 
performing WikiRank
on them to get 
performing 
related articles and their keywords 
related articles and their keywords 
–– A way to find higher level concepts not 
A way to find higher level concepts not 
mentioned like “Revolutionary War” or 
mentioned like “Revolutionary War” or 
“United States History” from a set of 
“United States History” from a set of 
battles.
battles.

16

